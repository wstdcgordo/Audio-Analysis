{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***This code is GPU-enabled.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For installing PyTorch with GPU, it will depend on the CUDA version installed, refer to https://pytorch.org/get-started/locally/. Also refer here for a CPU one.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using magic commands, it's `%` for VS Code but `!` for local Jupyter notebook/Google Colab. It's better to use these commands to avoid dependency conflicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Installing the required packages\n",
    "# %pip install numpy librosa soundfile transformers tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install ffmpeg\n",
    "# %pip install python-ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install torch (CPU)\n",
    "# %pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The cell above is for CPU, for GPU usage, refer to this link: https://www.youtube.com/watch?v=NrJz3ACosJA&ab_channel=LearnwithZORO*\n",
    "\n",
    "*Tested on **Windows**, not sure if GPU-utilization would work on Mac, but best to opt for CPU in the meantime.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Installing deepfilternet\n",
    "# %pip install deepfilterlib\n",
    "# %pip install deepfilternet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For `deepfilternet`, you need to install **Visual Studio** (as well as additional Visual Studio Packages, not just Visual Studio Code). You also need to install libraries such as `deepfilterlib` and `ffmpeg-python`, as they are all dependencies of `deepfilternet` and may not be included in `pip` installation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch, os\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.cuda.get_device_name(0))  # GPU model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the first line indicates `True`, it means `torch` detected a GPU that it will use, and the second line indicates the specific graphics card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below imports necessary libraries. This includes those needed for audio-related Python tasks (`loguru`, `librosa`, `soundfile`, `ffmpeg`, `deepfilternet`/`df`), and `transformers` from Huggingface (for models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.comNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting ffmpeg-python\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting python-ffmpeg\n",
      "  Downloading python_ffmpeg-2.0.12-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting future (from ffmpeg-python)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: pyee in c:\\users\\ebo\\anaconda3\\envs\\odeon\\lib\\site-packages (from python-ffmpeg) (12.1.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ebo\\anaconda3\\envs\\odeon\\lib\\site-packages (from python-ffmpeg) (4.12.2)\n",
      "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Downloading python_ffmpeg-2.0.12-py3-none-any.whl (14 kB)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Installing collected packages: future, python-ffmpeg, ffmpeg-python\n",
      "Successfully installed ffmpeg-python-0.2.0 future-1.0.0 python-ffmpeg-2.0.12\n"
     ]
    }
   ],
   "source": [
    "%pip install ffmpeg-python python-ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ebo\\anaconda3\\envs\\odeon\\Lib\\site-packages\\df\\io.py:9: UserWarning: `torchaudio.backend.common.AudioMetaData` has been moved to `torchaudio.AudioMetaData`. Please update the import path.\n",
      "  from torchaudio.backend.common import AudioMetaData\n",
      "c:\\Users\\Ebo\\anaconda3\\envs\\odeon\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings, librosa, soundfile as sf, gc, glob, pandas as pd, ffmpeg, numpy as np\n",
    "from df import enhance, init_df\n",
    "from transformers import pipeline, AutoModelForAudioClassification, AutoConfig\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_audio_files(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Enhances audio files in the input_folder and saves them in output_folder.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_folder (str): Directory containing the original audio files.\n",
    "    - output_folder (str): Directory where enhanced audio files will be saved.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Initialize the model and its state once outside the loop\n",
    "    model, df_state, _ = init_df()  # Load default model\n",
    "\n",
    "    # Process each audio file in the input folder\n",
    "    for file_path in glob.glob(os.path.join(input_folder, '*')):\n",
    "        try:\n",
    "            print(f\"Processing {file_path} ...\")\n",
    "            y, sr = librosa.load(file_path, sr=None)  # Load audio file\n",
    "\n",
    "            # Convert to PyTorch tensor\n",
    "            y_tensor = torch.from_numpy(y).float().unsqueeze(0)\n",
    "\n",
    "            # Enhance the audio\n",
    "            enhanced_audio = enhance(model, df_state, y_tensor)\n",
    "\n",
    "            # Convert back to NumPy array\n",
    "            if isinstance(enhanced_audio, torch.Tensor):\n",
    "                enhanced_audio_np = enhanced_audio.cpu().detach().numpy()\n",
    "            else:\n",
    "                enhanced_audio_np = enhanced_audio\n",
    "\n",
    "            # Remove extra batch dimension if present\n",
    "            if enhanced_audio_np.ndim > 1 and enhanced_audio_np.shape[0] == 1:\n",
    "                enhanced_audio_np = enhanced_audio_np[0]\n",
    "\n",
    "            # Prepare output file name\n",
    "            base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "            output_file = os.path.join(output_folder, base_name + '.wav')\n",
    "\n",
    "            # Save the enhanced audio\n",
    "            sf.write(output_file, enhanced_audio_np, sr)\n",
    "            print(f\"Enhanced audio saved to {output_file}\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-23 20:06:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on torch 2.6.0+cu126\u001b[0m\n",
      "\u001b[32m2025-02-23 20:06:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on host LAPTOP-5IMR3DTG\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-23 20:06:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mLoading model settings of DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2025-02-23 20:06:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mUsing DeepFilterNet3 model at C:\\Users\\Ebo\\AppData\\Local\\DeepFilterNet\\DeepFilterNet\\Cache\\DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2025-02-23 20:06:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mInitializing model `deepfilternet3`\u001b[0m\n",
      "\u001b[32m2025-02-23 20:06:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mFound checkpoint C:\\Users\\Ebo\\AppData\\Local\\DeepFilterNet\\DeepFilterNet\\Cache\\DeepFilterNet3\\checkpoints\\model_120.ckpt.best with epoch 120\u001b[0m\n",
      "\u001b[32m2025-02-23 20:06:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on device cuda:0\u001b[0m\n",
      "\u001b[32m2025-02-23 20:06:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mModel loaded\u001b[0m\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__31milmovement_video_7356107475910659346.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__31milmovement_video_7356107475910659346.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__amazingpuer_video_7372120567694003498.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__amazingpuer_video_7372120567694003498.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__amigongbayan_video_7354634652608417029.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__amigongbayan_video_7354634652608417029.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__ampoginiseangrabe_video_7359783776001592581.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__ampoginiseangrabe_video_7359783776001592581.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__barneykelboi_video_7357273092328131846.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__barneykelboi_video_7357273092328131846.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__candiselin86_video_7343834171418266926.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__candiselin86_video_7343834171418266926.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__chrismuellerrr_video_7367002368610733344.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__chrismuellerrr_video_7367002368610733344.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__data.discovery.ne_video_7365831384067280133.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__data.discovery.ne_video_7365831384067280133.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__defencecentral_video_7358720067804138759.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__defencecentral_video_7358720067804138759.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__defencecentral_video_7365453795196767496.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__defencecentral_video_7365453795196767496.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__dhadungdhudhang_video_7369419550409952517.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__dhadungdhudhang_video_7369419550409952517.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__frontline_focus_video_7369187514759892267.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__frontline_focus_video_7369187514759892267.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__groovy.moovies_video_7354514056130121002.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__groovy.moovies_video_7354514056130121002.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__hoetohauswife_video_7343755764932169003.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__hoetohauswife_video_7343755764932169003.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__karistocracy_video_7371753750253358341.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__karistocracy_video_7371753750253358341.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__katrina.roshan_video_7362897841338993938.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__katrina.roshan_video_7362897841338993938.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__katrina.roshan_video_7363637074685119752.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__katrina.roshan_video_7363637074685119752.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__kendrickspeaks_video_7351305598840868102.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__kendrickspeaks_video_7351305598840868102.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__laowailong_video_7372154025862548768.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__laowailong_video_7372154025862548768.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__leahandphillip_video_7354163748136914218.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__leahandphillip_video_7354163748136914218.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__literacycorner_video_7366434466925022469.mp3 ...\n",
      "Error processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__literacycorner_video_7366434466925022469.mp3: cuDNN error: CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input.\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__lucdep_lucxau_video_7349525902902004999.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__lucdep_lucxau_video_7349525902902004999.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__lucdep_lucxau_video_7360540154794151175.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__lucdep_lucxau_video_7360540154794151175.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__ludsg__video_7356408720294743301.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__ludsg__video_7356408720294743301.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__maceciliavillarosa_video_7358722386209918213.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__maceciliavillarosa_video_7358722386209918213.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__maceciliavillarosa_video_7364678277903961350.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__maceciliavillarosa_video_7364678277903961350.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__maceciliavillarosa_video_7367730056753319174.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__maceciliavillarosa_video_7367730056753319174.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__mdraselahmed262_video_7372189301586627873.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__mdraselahmed262_video_7372189301586627873.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__misscc.vibrantvibes_video_7367180726376090885.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__misscc.vibrantvibes_video_7367180726376090885.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__mr.rey_ytc_video_7345251727337082117.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__mr.rey_ytc_video_7345251727337082117.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__naughtyneo_4_video_7349534158236044550.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__naughtyneo_4_video_7349534158236044550.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__ncuscr1966_video_7346673264325922091.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__ncuscr1966_video_7346673264325922091.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__ncuscr1966_video_7348102797650332971.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__ncuscr1966_video_7348102797650332971.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__nikkoortizofficial_video_7353723429075340587.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__nikkoortizofficial_video_7353723429075340587.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__pmmarket_video_7343312379419118891.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__pmmarket_video_7343312379419118891.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__pointmysoulnorth_video_7361312843553197354.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__pointmysoulnorth_video_7361312843553197354.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__rathbonemakesmusic_video_7358156167845285166.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__rathbonemakesmusic_video_7358156167845285166.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__rxndy.edits_video_7368209198888406314.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__rxndy.edits_video_7368209198888406314.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__socialmediasoup_video_7352841535093771525.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__socialmediasoup_video_7352841535093771525.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__stephenli84_video_7368990263047507205.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__stephenli84_video_7368990263047507205.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__tiktoknewsshop1_video_7355477821193522437.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__tiktoknewsshop1_video_7355477821193522437.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__ukhiddengems_video_7372281505588038944.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__ukhiddengems_video_7372281505588038944.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__user4810040930193_video_7360597455030734126.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__user4810040930193_video_7360597455030734126.wav\n",
      "\n",
      "Processing ../data/With Backgorund Noise/Cleared\\https___www.tiktok.com__user4831685481257_video_7343252750685244715.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/With Background Noise\\https___www.tiktok.com__user4831685481257_video_7343252750685244715.wav\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute\n",
    "enhance_audio_files(input_folder=\"../data/With Backgorund Noise/Cleared\", output_folder=\"../data/Enhanced/With Background Noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-23 20:08:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mLoading model settings of DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2025-02-23 20:08:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mUsing DeepFilterNet3 model at C:\\Users\\Ebo\\AppData\\Local\\DeepFilterNet\\DeepFilterNet\\Cache\\DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2025-02-23 20:08:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mInitializing model `deepfilternet3`\u001b[0m\n",
      "\u001b[32m2025-02-23 20:08:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mFound checkpoint C:\\Users\\Ebo\\AppData\\Local\\DeepFilterNet\\DeepFilterNet\\Cache\\DeepFilterNet3\\checkpoints\\model_120.ckpt.best with epoch 120\u001b[0m\n",
      "\u001b[32m2025-02-23 20:08:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on device cuda:0\u001b[0m\n",
      "\u001b[32m2025-02-23 20:08:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mModel loaded\u001b[0m\n",
      "Processing ../data/Mixed Interviewer and Speaker\\https___www.tiktok.com__asiatoday111_video_7344992449472761094.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/Mixed Interviewer and Speaker\\https___www.tiktok.com__asiatoday111_video_7344992449472761094.wav\n",
      "\n",
      "Processing ../data/Mixed Interviewer and Speaker\\https___www.tiktok.com__asiatoday111_video_7358029354183560454.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/Mixed Interviewer and Speaker\\https___www.tiktok.com__asiatoday111_video_7358029354183560454.wav\n",
      "\n",
      "Processing ../data/Mixed Interviewer and Speaker\\https___www.tiktok.com__asiatoday111_video_7366471777456901381.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/Mixed Interviewer and Speaker\\https___www.tiktok.com__asiatoday111_video_7366471777456901381.wav\n",
      "\n",
      "Processing ../data/Mixed Interviewer and Speaker\\https___www.tiktok.com__asiatoday111_video_7366784568474553606.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/Mixed Interviewer and Speaker\\https___www.tiktok.com__asiatoday111_video_7366784568474553606.wav\n",
      "\n",
      "Processing ../data/Mixed Interviewer and Speaker\\https___www.tiktok.com__censoredvoice_video_7361515352229973291.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/Mixed Interviewer and Speaker\\https___www.tiktok.com__censoredvoice_video_7361515352229973291.wav\n",
      "\n",
      "Processing ../data/Mixed Interviewer and Speaker\\https___www.tiktok.com__censoredvoice_video_7361718963006393643.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/Mixed Interviewer and Speaker\\https___www.tiktok.com__censoredvoice_video_7361718963006393643.wav\n",
      "\n",
      "Processing ../data/Mixed Interviewer and Speaker\\https___www.tiktok.com__ping_sa_2025_video_7354219171904851205.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/Mixed Interviewer and Speaker\\https___www.tiktok.com__ping_sa_2025_video_7354219171904851205.wav\n",
      "\n",
      "Processing ../data/Mixed Interviewer and Speaker\\https___www.tiktok.com__politiko_ph_video_7356240172603755794.mp3 ...\n",
      "Enhanced audio saved to ../data/Enhanced/Mixed Interviewer and Speaker\\https___www.tiktok.com__politiko_ph_video_7356240172603755794.wav\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enhance_audio_files(input_folder=\"../data/Mixed Interviewer and Speaker\", output_folder=\"../data/Enhanced/Mixed Interviewer and Speaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models (emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Emotions",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d2fc8552-6f84-4605-a00a-75a535bfbfa3",
       "rows": [
        [
         "0",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "['angry', 'calm', 'disgust', 'fearful', 'happy', 'neutral', 'sad', 'surprised']"
        ],
        [
         "1",
         "firdhokk/speech-emotion-recognition-with-openai-whisper-large-v3",
         "['angry', 'disgust', 'fearful', 'happy', 'neutral', 'sad', 'surprised']"
        ],
        [
         "2",
         "firdhokk/speech-emotion-recognition-with-facebook-wav2vec2-large-xlsr-53",
         "['angry', 'disgust', 'fearful', 'happy', 'neutral', 'sad', 'surprised']"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-...</td>\n",
       "      <td>[angry, calm, disgust, fearful, happy, neutral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>firdhokk/speech-emotion-recognition-with-opena...</td>\n",
       "      <td>[angry, disgust, fearful, happy, neutral, sad,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>firdhokk/speech-emotion-recognition-with-faceb...</td>\n",
       "      <td>[angry, disgust, fearful, happy, neutral, sad,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model  \\\n",
       "0  ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-...   \n",
       "1  firdhokk/speech-emotion-recognition-with-opena...   \n",
       "2  firdhokk/speech-emotion-recognition-with-faceb...   \n",
       "\n",
       "                                            Emotions  \n",
       "0  [angry, calm, disgust, fearful, happy, neutral...  \n",
       "1  [angry, disgust, fearful, happy, neutral, sad,...  \n",
       "2  [angry, disgust, fearful, happy, neutral, sad,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = [\n",
    "    \"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\",\n",
    "    \"firdhokk/speech-emotion-recognition-with-openai-whisper-large-v3\",\n",
    "    \"firdhokk/speech-emotion-recognition-with-facebook-wav2vec2-large-xlsr-53\"\n",
    "]\n",
    "\n",
    "# Loop through each model and print its emotion classes\n",
    "model_data = []\n",
    "for model_name in models:\n",
    "    try:\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        emotions = list(config.id2label.values())  # Extract emotion classes\n",
    "        model_data.append({\"Model\": model_name, \"Emotions\": emotions})\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model {model_name}: {e}\")\n",
    "        model_data.append({\"Model\": model_name, \"Emotions\": \"Error loading emotions\"})\n",
    "\n",
    "# Create DataFrame\n",
    "df_models = pd.DataFrame(model_data)\n",
    "\n",
    "# Display the expanded DataFrame\n",
    "display(df_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running/evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is dedicated for **GPU usage**, including a function that will automatically clear caches after every audio processed to avoid GPU running out of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: GPU\n",
      "Processing with model 1: ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\n",
      "WARNING:tensorflow:From c:\\Users\\Ebo\\anaconda3\\envs\\odeon\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition were not used when initializing Wav2Vec2ForSequenceClassification: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.output.bias', 'classifier.output.weight']\n",
      "- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with model 2: firdhokk/speech-emotion-recognition-with-openai-whisper-large-v3\n",
      "Processing with model 3: firdhokk/speech-emotion-recognition-with-facebook-wav2vec2-large-xlsr-53\n"
     ]
    }
   ],
   "source": [
    "audio_folder = r'../data/Enhanced/Mixed Interviewer and Speaker'\n",
    "audio_files = [f for f in os.listdir(audio_folder) if f.endswith(\".wav\")]\n",
    "\n",
    "device = 0\n",
    "print(f\"Device: {'GPU' if device == 0 else 'CPU'}\")\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for i, model_name in enumerate(models):\n",
    "    print(f\"Processing with model {i + 1}: {model_name}\")\n",
    "    try:\n",
    "        emotion_pipeline = pipeline(\"audio-classification\", model=model_name, device=device)\n",
    "\n",
    "        for audio_file in audio_files:\n",
    "            audio_path = os.path.join(audio_folder, audio_file)\n",
    "            try:\n",
    "                results = emotion_pipeline(audio_path)\n",
    "                for result in results:\n",
    "                    all_data.append({\n",
    "                        \"File\": audio_file,\n",
    "                        \"Model\": model_name,\n",
    "                        \"Emotion\": result[\"label\"],\n",
    "                        \"Score\": result[\"score\"]\n",
    "                    })\n",
    "            except RuntimeError as e:\n",
    "                if \"CUDA out of memory\" in str(e):\n",
    "                    print(\"Out of memory! Switching to CPU.\")\n",
    "                    emotion_pipeline = pipeline(\"audio-classification\", model=model_name, device=-1)\n",
    "                    results = emotion_pipeline(audio_path)\n",
    "                    for result in results:\n",
    "                        all_data.append({\n",
    "                            \"File\": audio_file,\n",
    "                            \"Model\": model_name,\n",
    "                            \"Emotion\": result[\"label\"],\n",
    "                            \"Score\": result[\"score\"]\n",
    "                        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error with model {model_name}: {e}\")\n",
    "\n",
    "    # Cleanup\n",
    "    del emotion_pipeline\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "df = pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "File",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Emotion",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c973b8f0-5696-43d2-b5b4-4001c6c86166",
       "rows": [
        [
         "0",
         "https___www.tiktok.com__asiatoday111_video_7344992449472761094.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "disgust",
         "0.1347484439611435"
        ],
        [
         "1",
         "https___www.tiktok.com__asiatoday111_video_7344992449472761094.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "calm",
         "0.129842609167099"
        ],
        [
         "2",
         "https___www.tiktok.com__asiatoday111_video_7344992449472761094.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "fearful",
         "0.12752310931682587"
        ],
        [
         "3",
         "https___www.tiktok.com__asiatoday111_video_7344992449472761094.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "surprised",
         "0.1258566528558731"
        ],
        [
         "4",
         "https___www.tiktok.com__asiatoday111_video_7344992449472761094.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "angry",
         "0.12446393817663193"
        ],
        [
         "5",
         "https___www.tiktok.com__asiatoday111_video_7358029354183560454.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "calm",
         "0.13153794407844543"
        ],
        [
         "6",
         "https___www.tiktok.com__asiatoday111_video_7358029354183560454.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "disgust",
         "0.13127931952476501"
        ],
        [
         "7",
         "https___www.tiktok.com__asiatoday111_video_7358029354183560454.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "fearful",
         "0.1281605064868927"
        ],
        [
         "8",
         "https___www.tiktok.com__asiatoday111_video_7358029354183560454.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "happy",
         "0.1276433914899826"
        ],
        [
         "9",
         "https___www.tiktok.com__asiatoday111_video_7358029354183560454.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "angry",
         "0.12564796209335327"
        ],
        [
         "10",
         "https___www.tiktok.com__asiatoday111_video_7366471777456901381.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "calm",
         "0.1327640414237976"
        ],
        [
         "11",
         "https___www.tiktok.com__asiatoday111_video_7366471777456901381.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "neutral",
         "0.13041606545448303"
        ],
        [
         "12",
         "https___www.tiktok.com__asiatoday111_video_7366471777456901381.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "disgust",
         "0.12674613296985626"
        ],
        [
         "13",
         "https___www.tiktok.com__asiatoday111_video_7366471777456901381.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "fearful",
         "0.12488618493080139"
        ],
        [
         "14",
         "https___www.tiktok.com__asiatoday111_video_7366471777456901381.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "happy",
         "0.12453386932611465"
        ],
        [
         "15",
         "https___www.tiktok.com__asiatoday111_video_7366784568474553606.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "disgust",
         "0.13445457816123962"
        ],
        [
         "16",
         "https___www.tiktok.com__asiatoday111_video_7366784568474553606.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "calm",
         "0.1314947009086609"
        ],
        [
         "17",
         "https___www.tiktok.com__asiatoday111_video_7366784568474553606.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "angry",
         "0.12659968435764313"
        ],
        [
         "18",
         "https___www.tiktok.com__asiatoday111_video_7366784568474553606.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "fearful",
         "0.12657585740089417"
        ],
        [
         "19",
         "https___www.tiktok.com__asiatoday111_video_7366784568474553606.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "surprised",
         "0.12446463108062744"
        ],
        [
         "20",
         "https___www.tiktok.com__censoredvoice_video_7361515352229973291.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "disgust",
         "0.13545802235603333"
        ],
        [
         "21",
         "https___www.tiktok.com__censoredvoice_video_7361515352229973291.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "calm",
         "0.12949852645397186"
        ],
        [
         "22",
         "https___www.tiktok.com__censoredvoice_video_7361515352229973291.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "fearful",
         "0.12486099451780319"
        ],
        [
         "23",
         "https___www.tiktok.com__censoredvoice_video_7361515352229973291.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "angry",
         "0.12443333119153976"
        ],
        [
         "24",
         "https___www.tiktok.com__censoredvoice_video_7361515352229973291.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "happy",
         "0.12327943742275238"
        ],
        [
         "25",
         "https___www.tiktok.com__censoredvoice_video_7361718963006393643.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "disgust",
         "0.13198617100715637"
        ],
        [
         "26",
         "https___www.tiktok.com__censoredvoice_video_7361718963006393643.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "calm",
         "0.131687730550766"
        ],
        [
         "27",
         "https___www.tiktok.com__censoredvoice_video_7361718963006393643.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "fearful",
         "0.1268729567527771"
        ],
        [
         "28",
         "https___www.tiktok.com__censoredvoice_video_7361718963006393643.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "happy",
         "0.12415114045143127"
        ],
        [
         "29",
         "https___www.tiktok.com__censoredvoice_video_7361718963006393643.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "angry",
         "0.12290336936712265"
        ],
        [
         "30",
         "https___www.tiktok.com__ping_sa_2025_video_7354219171904851205.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "disgust",
         "0.13204991817474365"
        ],
        [
         "31",
         "https___www.tiktok.com__ping_sa_2025_video_7354219171904851205.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "calm",
         "0.1309313178062439"
        ],
        [
         "32",
         "https___www.tiktok.com__ping_sa_2025_video_7354219171904851205.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "happy",
         "0.12739768624305725"
        ],
        [
         "33",
         "https___www.tiktok.com__ping_sa_2025_video_7354219171904851205.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "angry",
         "0.12529149651527405"
        ],
        [
         "34",
         "https___www.tiktok.com__ping_sa_2025_video_7354219171904851205.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "fearful",
         "0.1234588548541069"
        ],
        [
         "35",
         "https___www.tiktok.com__politiko_ph_video_7356240172603755794.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "disgust",
         "0.13461259007453918"
        ],
        [
         "36",
         "https___www.tiktok.com__politiko_ph_video_7356240172603755794.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "calm",
         "0.12985679507255554"
        ],
        [
         "37",
         "https___www.tiktok.com__politiko_ph_video_7356240172603755794.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "happy",
         "0.12733601033687592"
        ],
        [
         "38",
         "https___www.tiktok.com__politiko_ph_video_7356240172603755794.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "fearful",
         "0.1259511560201645"
        ],
        [
         "39",
         "https___www.tiktok.com__politiko_ph_video_7356240172603755794.wav",
         "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
         "surprised",
         "0.12525655329227448"
        ],
        [
         "40",
         "https___www.tiktok.com__asiatoday111_video_7344992449472761094.wav",
         "firdhokk/speech-emotion-recognition-with-openai-whisper-large-v3",
         "happy",
         "0.500324547290802"
        ],
        [
         "41",
         "https___www.tiktok.com__asiatoday111_video_7344992449472761094.wav",
         "firdhokk/speech-emotion-recognition-with-openai-whisper-large-v3",
         "surprised",
         "0.265603631734848"
        ],
        [
         "42",
         "https___www.tiktok.com__asiatoday111_video_7344992449472761094.wav",
         "firdhokk/speech-emotion-recognition-with-openai-whisper-large-v3",
         "angry",
         "0.17223963141441345"
        ],
        [
         "43",
         "https___www.tiktok.com__asiatoday111_video_7344992449472761094.wav",
         "firdhokk/speech-emotion-recognition-with-openai-whisper-large-v3",
         "disgust",
         "0.023814184591174126"
        ],
        [
         "44",
         "https___www.tiktok.com__asiatoday111_video_7344992449472761094.wav",
         "firdhokk/speech-emotion-recognition-with-openai-whisper-large-v3",
         "fearful",
         "0.01841771975159645"
        ],
        [
         "45",
         "https___www.tiktok.com__asiatoday111_video_7358029354183560454.wav",
         "firdhokk/speech-emotion-recognition-with-openai-whisper-large-v3",
         "angry",
         "0.9961353540420532"
        ],
        [
         "46",
         "https___www.tiktok.com__asiatoday111_video_7358029354183560454.wav",
         "firdhokk/speech-emotion-recognition-with-openai-whisper-large-v3",
         "neutral",
         "0.001276201568543911"
        ],
        [
         "47",
         "https___www.tiktok.com__asiatoday111_video_7358029354183560454.wav",
         "firdhokk/speech-emotion-recognition-with-openai-whisper-large-v3",
         "happy",
         "0.0010351802920922637"
        ],
        [
         "48",
         "https___www.tiktok.com__asiatoday111_video_7358029354183560454.wav",
         "firdhokk/speech-emotion-recognition-with-openai-whisper-large-v3",
         "surprised",
         "0.0005963238072581589"
        ],
        [
         "49",
         "https___www.tiktok.com__asiatoday111_video_7358029354183560454.wav",
         "firdhokk/speech-emotion-recognition-with-openai-whisper-large-v3",
         "fearful",
         "0.0005865833954885602"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 120
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Model</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https___www.tiktok.com__asiatoday111_video_734...</td>\n",
       "      <td>ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0.134748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https___www.tiktok.com__asiatoday111_video_734...</td>\n",
       "      <td>ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-...</td>\n",
       "      <td>calm</td>\n",
       "      <td>0.129843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https___www.tiktok.com__asiatoday111_video_734...</td>\n",
       "      <td>ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-...</td>\n",
       "      <td>fearful</td>\n",
       "      <td>0.127523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https___www.tiktok.com__asiatoday111_video_734...</td>\n",
       "      <td>ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-...</td>\n",
       "      <td>surprised</td>\n",
       "      <td>0.125857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https___www.tiktok.com__asiatoday111_video_734...</td>\n",
       "      <td>ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-...</td>\n",
       "      <td>angry</td>\n",
       "      <td>0.124464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>https___www.tiktok.com__politiko_ph_video_7356...</td>\n",
       "      <td>firdhokk/speech-emotion-recognition-with-faceb...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.999698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>https___www.tiktok.com__politiko_ph_video_7356...</td>\n",
       "      <td>firdhokk/speech-emotion-recognition-with-faceb...</td>\n",
       "      <td>angry</td>\n",
       "      <td>0.000165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>https___www.tiktok.com__politiko_ph_video_7356...</td>\n",
       "      <td>firdhokk/speech-emotion-recognition-with-faceb...</td>\n",
       "      <td>surprised</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>https___www.tiktok.com__politiko_ph_video_7356...</td>\n",
       "      <td>firdhokk/speech-emotion-recognition-with-faceb...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>https___www.tiktok.com__politiko_ph_video_7356...</td>\n",
       "      <td>firdhokk/speech-emotion-recognition-with-faceb...</td>\n",
       "      <td>fearful</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  File  \\\n",
       "0    https___www.tiktok.com__asiatoday111_video_734...   \n",
       "1    https___www.tiktok.com__asiatoday111_video_734...   \n",
       "2    https___www.tiktok.com__asiatoday111_video_734...   \n",
       "3    https___www.tiktok.com__asiatoday111_video_734...   \n",
       "4    https___www.tiktok.com__asiatoday111_video_734...   \n",
       "..                                                 ...   \n",
       "115  https___www.tiktok.com__politiko_ph_video_7356...   \n",
       "116  https___www.tiktok.com__politiko_ph_video_7356...   \n",
       "117  https___www.tiktok.com__politiko_ph_video_7356...   \n",
       "118  https___www.tiktok.com__politiko_ph_video_7356...   \n",
       "119  https___www.tiktok.com__politiko_ph_video_7356...   \n",
       "\n",
       "                                                 Model    Emotion     Score  \n",
       "0    ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-...    disgust  0.134748  \n",
       "1    ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-...       calm  0.129843  \n",
       "2    ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-...    fearful  0.127523  \n",
       "3    ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-...  surprised  0.125857  \n",
       "4    ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-...      angry  0.124464  \n",
       "..                                                 ...        ...       ...  \n",
       "115  firdhokk/speech-emotion-recognition-with-faceb...      happy  0.999698  \n",
       "116  firdhokk/speech-emotion-recognition-with-faceb...      angry  0.000165  \n",
       "117  firdhokk/speech-emotion-recognition-with-faceb...  surprised  0.000075  \n",
       "118  firdhokk/speech-emotion-recognition-with-faceb...    disgust  0.000035  \n",
       "119  firdhokk/speech-emotion-recognition-with-faceb...    fearful  0.000017  \n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same model for applying into raw audios to see if there is a difference in emotion detection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odeon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
